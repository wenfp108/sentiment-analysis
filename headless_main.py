import os
import json
import base64
import requests
import numpy as np
from datetime import datetime, timezone, timedelta

# å¼•å…¥é¡¹ç›®æ¨¡å—
from src.pipelines import top_posts_subreddit_pipeline
from src.logger_config import setup_logger

logger = setup_logger()

# === é…ç½®åŒº ===
COMMAND_REPO = "wenfp108/Central-Bank"
OUTPUT_ROOT = "reddit/sentiment" # å­˜åˆ° Central Bank çš„å“ªä¸ªæ–‡ä»¶å¤¹
POOL_SIZE = 10     # æŠ“æ¯ä¸ªè®ºå›çš„å‰ 10 è´´
COMMENT_LIMIT = 5  # (æ­¤å‚æ•°åœ¨ get_reddit_data å†…éƒ¨å·²è¢«å›ºå®šä¸º 3ï¼Œä½†éœ€ä¿ç•™ä¼ å‚)

def get_github_headers():
    token = os.environ.get("GITHUB_TOKEN") # å¿…é¡»åœ¨ Action Secrets é‡Œé…å¥½
    if not token:
        logger.error("âŒ GITHUB_TOKEN not found!")
        return None
    return {
        "Authorization": f"Bearer {token}",
        "Accept": "application/vnd.github.v3+json"
    }

def fetch_missions():
    """å» Central-Bank çš„ Issue åŒºæ‰¾ä»»åŠ¡"""
    headers = get_github_headers()
    if not headers: return {}
    
    try:
        url = f"https://api.github.com/repos/{COMMAND_REPO}/issues?state=open"
        resp = requests.get(url, headers=headers, timeout=10)
        if resp.status_code != 200: return {}
        
        missions = {}
        for issue in resp.json():
            title = issue.get('title', '').lower()
            # è¯†åˆ«æ ‡é¢˜å¸¦ [reddit] çš„ Issue
            if '[reddit]' in title:
                # æå– Body é‡Œçš„å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”
                sub_name = title.replace('[reddit]', '').strip()
                keywords = issue.get('body', '').strip().split(',') if issue.get('body') else []
                missions[sub_name] = keywords
        return missions
    except Exception as e:
        logger.error(f"Fetch missions failed: {e}")
        return {}

def sync_to_central_bank(data_batch):
    """æŠŠç»“æœå­˜å› Central-Bank"""
    headers = get_github_headers()
    if not headers: return

    # ç”ŸæˆæŒ‰å¤©å½’æ¡£çš„æ–‡ä»¶å: reddit/sentiment/2026-02-04.json
    now = datetime.now(timezone(timedelta(hours=8)))
    date_str = now.strftime('%Y-%m-%d')
    path = f"{OUTPUT_ROOT}/{date_str}.json"
    
    api_url = f"https://api.github.com/repos/{COMMAND_REPO}/contents/{path}"
    
    # 1. å…ˆæ‹‰å–å½“å¤©çš„æ—§æ•°æ® (Pull)
    existing_data = []
    sha = None
    try:
        resp = requests.get(api_url, headers=headers)
        if resp.status_code == 200:
            file_info = resp.json()
            sha = file_info['sha']
            content = base64.b64decode(file_info['content']).decode('utf-8')
            existing_data = json.loads(content)
    except: pass
    
    # 2. åˆå¹¶æ–°æ•°æ® (Merge)
    # è¿™é‡Œçš„ data_batch æ˜¯ä¸€ä¸ªåŒ…å« timestamp å’Œ data åˆ—è¡¨çš„å­—å…¸
    existing_data.append(data_batch)
    
    # 3. æ¨é€å›å» (Push)
    try:
        new_content = json.dumps(existing_data, indent=2, ensure_ascii=False)
        b64_content = base64.b64encode(new_content.encode('utf-8')).decode('utf-8')
        
        payload = {
            "message": f"ğŸ¤– Reddit Update: {now.strftime('%H:%M')}",
            "content": b64_content,
            "branch": "main"
        }
        if sha: payload["sha"] = sha
        
        requests.put(api_url, headers=headers, json=payload)
        logger.info(f"âœ… Data synced to {path}")
    except Exception as e:
        logger.error(f"Sync failed: {e}")

def run():
    # 1. é¢†ä»»åŠ¡
    missions = fetch_missions()
    if not missions:
        logger.info("ğŸ’¤ No missions found in Issues.")
        return
        
    logger.info(f"ğŸ›¡ï¸ Missions accepted: {list(missions.keys())}")
    
    batch_results = []
    
    # 2. æ‰§è¡Œä»»åŠ¡
    for sub, keywords in missions.items():
        try:
            # è°ƒç”¨ Pipeline
            df = top_posts_subreddit_pipeline(sub, POOL_SIZE, COMMENT_LIMIT, "Hot")
            if df.empty: continue
            
            # é€‰å‡º Champion (å¾—åˆ†æœ€é«˜çš„ 5 ä¸ª)
            # rank_score = åŸºç¡€çƒ­åº¦(score) * æƒ…ç»ªå¼ºåº¦(abs(vibe))
            # æ³¨æ„ï¼švibe_val åœ¨ pipeline é‡Œå·²ç»ç®—å¥½äº†
            df['rank_score'] = df['score'] * (df['vibe_val'].abs() + 0.1)
            champions = df.sort_values('rank_score', ascending=False).head(5)
            
            post_list = []
            for _, row in champions.iterrows():
                post_list.append({
                    "title": row['title'],
                    "url": row['url'],
                    "score": int(row['score']),
                    "vibe": float(row['vibe_val']), # æƒ…ç»ªåˆ†
                    "summary": row['clean_text'][:100] # æ‘˜è¦
                })
            
            batch_results.append({
                "subreddit": sub,
                "avg_sentiment": float(df['vibe_val'].mean()),
                "champions": post_list
            })
            
        except Exception as e:
            logger.error(f"Failed to process r/{sub}: {e}")
            
    # 3. ä¸Šä¼ ç»“æœ
    if batch_results:
        payload = {
            "timestamp": datetime.now(timezone(timedelta(hours=8))).isoformat(),
            "data": batch_results
        }
        sync_to_central_bank(payload)

if __name__ == "__main__":
    run()
